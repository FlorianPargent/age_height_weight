{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item Construction Rules Revisited: Learnings from Measurement of\n",
    "\n",
    "Latent Variables with Gold-Standard Items\n",
    "\n",
    "Kathryn Eichhorn [![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==)](https://orcid.org/0000-0003-3676-9420) (University of the Bundeswehr Munich)  \n",
    "Markus Bühner [![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==)](https://orcid.org/0000-0002-0597-8708) (LMU Munich)  \n",
    "Florian Pargent [![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==)](https://orcid.org/0000-0002-2388-553X) (LMU Munich)  \n",
    "Janika Saretzki [![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==)](https://orcid.org/0000-0002-6536-8266) (LMU Munich, University of Graz, Charlotte Fresenius University of Psychology)  \n",
    "Larissa Sust [![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==)](https://orcid.org/0000-0002-3389-1626) (LMU Munich)  \n",
    "Jonas Hauck [![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==)](https://orcid.org/0009-0002-8872-0530) (University of Regensburg)  \n",
    "Sven Hilbert [![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==)](https://orcid.org/0000-0001-5808-8357) (University of Regensburg)  \n",
    "2025-07-18\n",
    "\n",
    "This article investigates whether gold-standard items are helpful for questionnaire construction. Based on cognitive interviews ($N$ = 8) and a pilot study ($N$ = 390) with an initial item set, three 12-item scales were constructed to measure the physical traits of body height, body weight, and age. We collected data on these scales using response formats with either two ($N$ = 921) or six ($N$ = 933) categories. We also collected numeric self-reports of body weight, body height, and age as gold-standard items. Confirmatory factor analyses revealed that the gold-standard items did not consistently exhibit the highest loading on their corresponding latent variable. Furthermore, when controlling for the self-reported physical body height, body weight, and age as gold-standard items, as well as gender, we did not always find an interpretable, systematic residual variance. Finally, the pattern of correlations between the latent variables did not reflect the correlations between the self-reported gold-standard items, suggesting that the item scales and the gold-standard items do not have the same validity. While these results are consistent with previous studies, our analyses also showed that items with two response categories were at least as valid as those with six categories, contradicting past recommendations. When constructing a questionnaire, we would argue that the items intended to measure the latent variable most directly should have the highest loading on that variable. If this is not the case, the content validity is questionable at best. The implications are that intensive cognitive pretesting is necessary. Questionnaires with different response formats should be compared empirically and hypotheses about which items best represent the latent variable should be tested.\n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "# Item Construction Rules Revisited: Learnings from Measurement of Latent Variables with Gold-Standard Items\n",
    "\n",
    "  \n",
    "\n",
    "Kathryn Eichhorn<sup>1</sup>, Markus Bühner<sup>2</sup>, Florian Pargent<sup>2</sup>, Janika Saretzki<sup>2,3,4</sup>, Larissa Sust<sup>2</sup>, Jonas Hauck<sup>5</sup>, and Sven Hilbert<sup>5</sup>\n",
    "\n",
    "<sup>1</sup>Institute of Psychology, University of the Bundeswehr Munich\n",
    "\n",
    "<sup>2</sup>Department of Psychology, LMU Munich\n",
    "\n",
    "<sup>3</sup>Department of Psychology, University of Graz\n",
    "\n",
    "<sup>4</sup>Charlotte Fresenius University of Psychology\n",
    "\n",
    "<sup>5</sup>Faculty of Psychology, University of Regensburg\n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "# Author Note\n",
    "\n",
    "Kathryn Eichhorn ![Orcid ID Logo: A green circle with white letters ID](attachment:_extensions/wjschne/apaquarto/ORCID-iD_icon-vector.svg) <https://orcid.org/0000-0003-3676-9420>\n",
    "\n",
    "Markus Bühner ![Orcid ID Logo: A green circle with white letters ID](attachment:_extensions/wjschne/apaquarto/ORCID-iD_icon-vector.svg) <https://orcid.org/0000-0002-0597-8708>\n",
    "\n",
    "Florian Pargent ![Orcid ID Logo: A green circle with white letters ID](attachment:_extensions/wjschne/apaquarto/ORCID-iD_icon-vector.svg) <https://orcid.org/0000-0002-2388-553X>\n",
    "\n",
    "Janika Saretzki ![Orcid ID Logo: A green circle with white letters ID](attachment:_extensions/wjschne/apaquarto/ORCID-iD_icon-vector.svg) <https://orcid.org/0000-0002-6536-8266>\n",
    "\n",
    "Larissa Sust ![Orcid ID Logo: A green circle with white letters ID](attachment:_extensions/wjschne/apaquarto/ORCID-iD_icon-vector.svg) <https://orcid.org/0000-0002-3389-1626>\n",
    "\n",
    "Jonas Hauck ![Orcid ID Logo: A green circle with white letters ID](attachment:_extensions/wjschne/apaquarto/ORCID-iD_icon-vector.svg) <https://orcid.org/0009-0002-8872-0530>\n",
    "\n",
    "Sven Hilbert ![Orcid ID Logo: A green circle with white letters ID](attachment:_extensions/wjschne/apaquarto/ORCID-iD_icon-vector.svg) <https://orcid.org/0000-0001-5808-8357>\n",
    "\n",
    "This is version 0 (last modification 2025-07-30) of our preprint to be published on PsyArXiv. All materials (reproducible manuscript, analysis code, datasets, codebooks, questionnaires) are available in the project’s repository on the Open Science Framework (OSF) at <https://osf.io/p7492/>. A Quarto Manuscripts website is hosted at <https://florianpargent.github.io/gold-standard-items/>. The data has previously been analyzed in the dissertation thesis of the first author at <https://doi.org/10.5282/edoc.23628>. As part of the dissertation, a preregistration was published at <https://osf.io/cz3uv/?view_only=9cac02db231b48629fea9ae53c3038b9> that differs from the analyses reported in the current manuscript. The authors declare that there were no conflicts of interest concerning the authorship or the publication of this article.\n",
    "\n",
    "Kathryn Eichhorn and Markus Bühner contributed equally to this manuscript. Author roles were classified using the Contributor Role Taxonomy (CRediT; <https://credit.niso.org/>): *Kathryn Eichhorn***: **conceptualization, investigation, resources, data curation, and writing – original draft. *Markus Bühner***: **formal analysis, supervision, and writing – original draft. *Florian Pargent***: **formal analysis, software, validation, and writing – review & editing. *Janika Saretzki***: **writing – review & editing. *Larissa Sust***: **writing – review & editing. *Jonas Hauck***: **writing – review & editing. *Sven Hilbert***: **conceptualization, supervision, and writing – review & editing\n",
    "\n",
    "Correspondence concerning this article should be addressed to Markus Bühner, Department of Psychology, LMU Munich, Leopoldstr. 13, D-80802 Munich 80802, Germany, Email: <buehner@lmu.de>\n",
    "\n",
    "# Abstract\n",
    "\n",
    "This article investigates whether gold-standard items are helpful for questionnaire construction. Based on cognitive interviews ($N$ = 8) and a pilot study ($N$ = 390) with an initial item set, three 12-item scales were constructed to measure the physical traits of body height, body weight, and age. We collected data on these scales using response formats with either two ($N$ = 921) or six ($N$ = 933) categories. We also collected numeric self-reports of body weight, body height, and age as gold-standard items. Confirmatory factor analyses revealed that the gold-standard items did not consistently exhibit the highest loading on their corresponding latent variable. Furthermore, when controlling for the self-reported physical body height, body weight, and age as gold-standard items, as well as gender, we did not always find an interpretable, systematic residual variance. Finally, the pattern of correlations between the latent variables did not reflect the correlations between the self-reported gold-standard items, suggesting that the item scales and the gold-standard items do not have the same validity. While these results are consistent with previous studies, our analyses also showed that items with two response categories were at least as valid as those with six categories, contradicting past recommendations. When constructing a questionnaire, we would argue that the items intended to measure the latent variable most directly should have the highest loading on that variable. If this is not the case, the content validity is questionable at best. The implications are that intensive cognitive pretesting is necessary. Questionnaires with different response formats should be compared empirically and hypotheses about which items best represent the latent variable should be tested."
   ],
   "attachments": {
    "_extensions/wjschne/apaquarto/ORCID-iD_icon-vector.svg": {
     "image/svg+xml": "PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPCEtLSBHZW5lcmF0b3I6IEFk\nb2JlIElsbHVzdHJhdG9yIDE5LjEuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246\nIDYuMDAgQnVpbGQgMCkgIC0tPgo8c3ZnIHZlcnNpb249IjEuMSIgaWQ9IkxheWVyXzEiIHhtbG5z\nPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMu\nb3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4IgoJIHZpZXdCb3g9IjAgMCAyNTYgMjU2IiBz\ndHlsZT0iZW5hYmxlLWJhY2tncm91bmQ6bmV3IDAgMCAyNTYgMjU2OyIgeG1sOnNwYWNlPSJwcmVz\nZXJ2ZSI+CjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+Cgkuc3Qwe2ZpbGw6I0E2Q0UzOTt9Cgkuc3Qx\ne2ZpbGw6I0ZGRkZGRjt9Cjwvc3R5bGU+CjxwYXRoIGNsYXNzPSJzdDAiIGQ9Ik0yNTYsMTI4YzAs\nNzAuNy01Ny4zLDEyOC0xMjgsMTI4QzU3LjMsMjU2LDAsMTk4LjcsMCwxMjhDMCw1Ny4zLDU3LjMs\nMCwxMjgsMEMxOTguNywwLDI1Niw1Ny4zLDI1NiwxMjh6Ii8+CjxnPgoJPHBhdGggY2xhc3M9InN0\nMSIgZD0iTTg2LjMsMTg2LjJINzAuOVY3OS4xaDE1LjR2NDguNFYxODYuMnoiLz4KCTxwYXRoIGNs\nYXNzPSJzdDEiIGQ9Ik0xMDguOSw3OS4xaDQxLjZjMzkuNiwwLDU3LDI4LjMsNTcsNTMuNmMwLDI3\nLjUtMjEuNSw1My42LTU2LjgsNTMuNmgtNDEuOFY3OS4xeiBNMTI0LjMsMTcyLjRoMjQuNQoJCWMz\nNC45LDAsNDIuOS0yNi41LDQyLjktMzkuN2MwLTIxLjUtMTMuNy0zOS43LTQzLjctMzkuN2gtMjMu\nN1YxNzIuNHoiLz4KCTxwYXRoIGNsYXNzPSJzdDEiIGQ9Ik04OC43LDU2LjhjMCw1LjUtNC41LDEw\nLjEtMTAuMSwxMC4xYy01LjYsMC0xMC4xLTQuNi0xMC4xLTEwLjFjMC01LjYsNC41LTEwLjEsMTAu\nMS0xMC4xCgkJQzg0LjIsNDYuNyw4OC43LDUxLjMsODguNyw1Ni44eiIvPgo8L2c+Cjwvc3ZnPg==\n"
    }
   },
   "id": "840c76e6-b0a2-4fa2-bfa0-af7242fa17c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading required package: tinylabels"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Attaching package: 'flextable'"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The following object is masked from 'package:papaja':\n",
      "\n",
      "    theme_apa"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
      "✔ dplyr     1.1.4     ✔ readr     2.1.5\n",
      "✔ forcats   1.0.0     ✔ stringr   1.5.1\n",
      "✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n",
      "✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n",
      "✔ purrr     1.1.0     "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ purrr::compose() masks flextable::compose()\n",
      "✖ dplyr::filter()  masks stats::filter()\n",
      "✖ dplyr::lag()     masks stats::lag()\n",
      "ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors"
     ]
    }
   ],
   "source": [
    "# load datasets and results objects\n",
    "# place chunk before the yaml header, so sample sizes can be reported in the abstract\n",
    "library(papaja)"
   ],
   "id": "252309e0-d162-4557-866f-45d17b3fc8c5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "Psychological researchers typically develop questionnaires and use latent variable modeling to test whether they measure the intended psychological construct ([Holt et al., 2010](#ref-tenholtScaleConstructionEvaluation2010)). According to the most applied test models (e.g., factor analytic models) especially item discrimination parameters are interpreted as how well items correlate with the latent variable (see [Lord et al., 1968](#ref-lordStatisticalTheoriesMental1968)). Highly correlated items with the latent variable indicate that these items are more important to measure the latent variable compared to items with lower correlations. Thus, the item discrimination parameter is typically used to assess the quality of an item measuring the latent variable.\n",
    "\n",
    "To assure that we obtain high item discrimination parameters it is essential to start with a precise definition of the latent variable. The definition is the starting point for deriving items with content validity. The item construction is believed to be theoretically sound if items are selected from a larger population of possible indicators of the latent variable in a representative manner to achieve high content validity and ensure that we measure the indented construct. Let us assume that we try to measure the latent variable *interpersonal warmth* with the following adjectives: *affectionate*, *friendly*, *talkative*, *unprejudiced*. We ask how well each adjective describes yourself from *not at all* (0) to *fully and entirely* (4) with five response categories. If these items measure warmth, they should at least all significantly correlate with the adjective warmth measured with the same response format. Even more, the warmth item should have the highest discrimination parameter conducting a factor analysis with empirical data, otherwise a different construct is measured, e.g., friendliness, in the case that the adjective *friendly* has the highest loading on the latent variable. This can be seen as a robustness check that the latent variable has the intended meaning. In the following sections, we refer to such items as *gold-standard items*.\n",
    "\n",
    "In this study, we construct scales for the “physical traits” *body height*, *body weight*, and *age* and compare them with a gold-standard item, that is, the numerical self-report of the respective physical property. We derive three assumptions that should hold if a valid measurement of the mentioned latent variables is possible. We base these assumptions on the relevant literature on previous studies, item wording, and response categories, which we will outline in the next section.\n",
    "\n",
    "## Theoretical Background\n",
    "\n",
    "### Evidence Using Gold-Standard Items\n",
    "\n",
    "To demonstrate the validity of psychological measurements and the practical utility of psychological measurement models, Bortolotti et al. ([2013](#ref-bortolottiRelevanceAdvantagesUsing2013)) compared psychological measurement with physical measurement. They constructed a scale with 27 items intended to assess body height. Using a response format with two response categories, participants were asked to respond to items such as “Do I think, I would do well in a basketball team?” ([Bortolotti et al., 2013, p. 2350](#ref-bortolottiRelevanceAdvantagesUsing2013)). At the end of the scale, participants were asked to report their actual height in centimeters, the self-reported physical gold-standard item. The parameters estimated from the latent variable body height were then compared with the physical, gold-standard measurements. The results revealed a strong correlation (.86, not corrected for disattenuation) between the estimated person parameters derived from a two-parameter logistic model and the self-reported physical height. Still, the gold-standard item did not exhibit the highest loading on the scale ([Bortolotti et al., 2013](#ref-bortolottiRelevanceAdvantagesUsing2013)). Van der Linden ([2016](#ref-vanderlindenUnidimensionalLogisticResponse2016)) also employed a height measurement based on items with two response categories (e.g., “I bump my head quite often.”, p. 27) to illustrate the usefulness of logistic item response models. According to the author, this approach is unusual, as body height appears to be a physical variable that can only be measured using a yardstick. However, differences in height influence behavior, making it quite plausible to view such behavioral indicators as proxies for body height and to derive a psychological measurement from them. The two examples suggest that, first, gold-standard items do not always have the highest loading on the latent variable. Second, measuring a “physical” latent variable might be a psychological representation of body height rather than a measure of physical body height.\n",
    "\n",
    "### Item Wording\n",
    "\n",
    "One important aspect of item construction is item wording. In this context, Pargent et al. ([2019](#ref-pargentCanMakeIt2019)) showed that the quality of item wording did, in fact, not impact model fit based on commonly used fit indices of confirmatory factor analyses. Sound item wording may not be crucial for achieving good model fit, but it clearly is for understanding the item correctly: For example, if a person does not correctly recognize an item with negative polarity, the person’s value on the scale is immediately over- or underestimated by a few points. In some cases, this can lead to considerable distortions in the test score. If a person does not understand the items correctly, their response cannot be valid, regardless of any model fit indicators (for an extreme example, see [Maul, 2017](#ref-maulRethinking2017)). Thus, it would be problematic to evaluate the quality of a questionnaire by solely looking at the model fit of the latent variable model, the discrimination parameters and/or reliability estimates. In this context, McNeish et al. ([2018](#ref-mcneishThornyRelationMeasurement2018)) stated that good fit indices (e.g., Root Mean Square Error of Approximation, RMSEA; Standardized Root Mean Square Residual, SRMR; and the Comparative Fit Index, CFI) must be considered together with measurement quality (reliability) and the size of standardized factor loadings. They showed examples where all fit indices were excellent, but the standardized item loadings were .40, and another model where the fit indices were inadequate, but the factor loadings were .90. Thus, fit indices can be misleading without considering the quality of measurement.\n",
    "\n",
    "### Response Scale\n",
    "\n",
    "Hilbert et al. ([2016](#ref-hilbertInfluenceResponseFormat2016)) presented initial evidence that different response scales might not measure the same latent variable. They found that the correlation (disattenuated for measurement error) between latent variables measured by identical items ranged only from .76 to .88 when using items with two versus five response categories and a visual analogue scale. The question arises: Which of these questionnaires measures the true construct? What is well known is how the number of response categories affects reliability estimates. A vast amount of literature compares different numbers of response categories for rating scale items. We quote some exemplary studies to demonstrate how complex and difficult it is to choose a reasonable number of response categories and highlight what we can conclude from their results. Preston and Colman ([2000](#ref-prestonOptimalNumberResponse2000)) reported that two response categories exhibited the lowest retest-reliability and a relatively poor validity and discriminating power. They recommend applying rating scales with at least seven response categories. In contrast, Lee and Paek ([2014, p. 663](#ref-leeSearchOptimalNumber2014)) concluded that “caution should be made if a scale has only two response categories, but that limitation may be overcome by manipulating other scale features, namely, scale length or item discrimination”. Weijters et al. ([2010](#ref-weijtersEffectRatingScale2010)) recommend rating scales with five fully labeled response categories for samples drawn from the general population. In their recommendations, the authors considered an extreme response style, responses to reversed items, and an acquiescence response style. However, Masuda et al. ([2017](#ref-masudaRespondentsLowMotivation2017)) found that low-motivated persons tend to use the middle category, implying that a middle category is not advisable. Similarly, Bradley et al. ([2015, p. 8](#ref-bradleyRatingScalesSurvey2015)) concluded from their study that “for constructing measures from survey responses, the inclusion of a neutral middle category distorts the data to the point where it is not possible to construct meaningful measures.” All in all, the reviewed literature suggests that to achieve high reliability, seven response categories seem the be useful, but there is also evidence to omit the middle category due to the inconsistent use of it. Thus, we infer that there is evidence to use rating scales with six response categories without a middle category.\n",
    "\n",
    "## Implications\n",
    "\n",
    "We quote from a review on the application of Item Response Theory (IRT) models and factor analyses ([Holt et al., 2010, p. 288](#ref-tenholtScaleConstructionEvaluation2010)): “In our opinion, researchers could take far better advantage of their theoretical knowledge and/or expectations by incorporating their a priori knowledge of the items and scales in the analyses. This should be reflected 1) by a more frequent application of confirmatory techniques, especially in the construction of new scales and 2) by adding interpretability of factors and content of items to the criteria used for model evaluation.” Building on this summary statement, the aforementioned research and recommendations, we assess three physical “traits” to replicate and extend previous findings. First, we constructed scales for body height, body weight, and age. Second, we used items with two response categories to replicate the results of Bortolotti et al. ([2013](#ref-bortolottiRelevanceAdvantagesUsing2013)) for body height. Third, we applied an additional format containing six response categories without a middle category which low-motivated persons tend to overuse (e.g., see [Masuda et al., 2017](#ref-masudaRespondentsLowMotivation2017)). We aimed to investigate whether 1) the results of Bortolotti et al. ([2013](#ref-bortolottiRelevanceAdvantagesUsing2013)) hold true for body height and similar physical traits, and whether 2) there really is a psychological component in self-report questionnaires of physical traits as assumed by Van der Linden ([2016](#ref-vanderlindenUnidimensionalLogisticResponse2016)). Furthermore, we assumed that items with six response categories have higher reliability and thus, higher loadings and better validity than those with two response categories ([Lee & Paek, 2014](#ref-leeSearchOptimalNumber2014); [Preston & Colman, 2000](#ref-prestonOptimalNumberResponse2000); [Weijters et al., 2010](#ref-weijtersEffectRatingScale2010)). The concrete assumptions underlying our research are the following:[1]\n",
    "\n",
    "-   *Assumption 1:* From a theoretical point of view, the self-reported physical body height, body weight, and age as the self-reported gold-standard items should have the highest factor loading (which is equivalent to a high correlation between the latent variable and the item applying a one-factor model) compared to other questionnaire items measuring the respective physical trait.\n",
    "\n",
    "-   *Assumption 2:* The measurement of physical traits with questionnaire items should have a psychological component because the self-reported physical measurement and gender (as there are gender differences in perception, see [McCreary, 2002](#ref-mccrearyGenderAgeDifferences2002)) cannot fully explain the item responses. Systematic correlated residuals should remain.\n",
    "\n",
    "-   *Assumption 3a, b:* The correlational pattern between the latent variables for the physical traits should correspond to the correlation of the self-reported gold-standard items (3a) and the factor loadings and reliability estimates should be higher for scales with 6-point response categories compared to 2-point response categories (3b).\n",
    "\n",
    "  \n",
    "\n",
    "# Methods\n",
    "\n",
    "All materials (reproducible manuscript, analysis code, datasets, codebooks, questionnaires) for this manuscript are openly available on the Open Science Framework (OSF) at <https://osf.io/p7492/>. A Quarto Manuscripts website presenting the manuscript and electronic supplementary materials is hosted at <https://florianpargent.github.io/gold-standard-items/>.\n",
    "\n",
    "## Item Construction\n",
    "\n",
    "First, we constructed items for the physical characteristics of body height, body weight, and age. Age was defined as chronological age or age in years, corresponding to the time elapsed since a person’s birth ([Montepare & Lachman, 1989](#ref-montepareYouReOnly1989); [Schwall, 2012](#ref-schwallDefiningAgeUsing2012)). Height was defined as the height of an upright person from the sole of the foot to the top of the head in centimeters, and body weight as the physical mass of a person in kilograms ([Martin, 1929](#ref-martinAnthropometrieAnleitungSelbstaendigen1929)). The initial items were developed by 124 psychology students (deductive item construction, [Burisch, 1984](#ref-burischApproachesPersonalityInventory1984)) and 24 persons (prototype approach, see [Broughton, 1984](#ref-broughtonPrototypeStrategyConstruction1984)) who deviated from the German population mean at least one standard deviation in the relevant characteristics (separately for women and men). The 24 persons were asked to think of prototypical behaviors for each construct to assess the whole spectrum of the latent variable. This process resulted in an initial set of 138 items (response categories were not tested). In a second step, we examined how these items were interpreted and whether they were connected to additional concepts unrelated to the constructs using cognitive interviews. We conducted interviews with a length of two to three hours and applied various cognitive procedures, including probing, paraphrasing, concurrent-think-aloud, and retrospective-think-aloud ([Prüfer & Rexroth, 1996](#ref-prueferVerfahrenEvaluationSurvey1996), [2005](#ref-prueferKognitiveInterviews2005)). The literature on cognitive interviews recommends five to 30 interviews but indicates that the most serious problems can already be identified with a small number of interviews ([Willis, 2005](#ref-willisCognitiveInterviewing2005)). The interviews were conducted with 8 people from the target group (4 women and 4 men) aged between 21 and 77 (*M* = 44.50, *SD* = 20.78). The level of education ranged from high school diploma to university degree. After the cognitive interviews, misleading items were reformulated or eliminated ([Faulbaum et al., 2009](#ref-faulbaumWasIstGute2009)), resulting in 61 remaining items. In a third step, these 61 items were pilot tested online on a new sample, which initially consisted of 456 people. However, we excluded 66 subjects because they had not completed the questionnaire, resulting in a sample of 390 participants aged between 18 and 77 years (*M* = 31.91, *SD* = 12.82), including 302 women (77.44 %) and 88 men (22.56 %). The level of education was distributed as follows: 0 % no school leaving certificate, 3.33 % secondary school leaving certificate/elementary school or equivalent, 17.18 % secondary school or equivalent, 35.90 % vocational baccalaureate or high school diploma, 40.77 % college degree or university degree, 2.82 % doctorate or habilitation. Out of all respondents, 95.38 % stated German as their native language. Based on these survey responses, we excluded items if a) their main item loading was not on the intended factor, b) their main and secondary loadings were almost equal, or c) they had loading below or equal to .30. Additionally, if (d) items had very similar content, items with lower loadings were excluded. More details on the process of item construction can be found in Eichhorn ([2019](#ref-eichhornItem2019)). We reproduced the exploratory factor analyses, item total correlations and reliability estimates that were computed in the final item selection stage and report them in our electronic supplementary materials. Based on these criteria 12 final items were selected for each physical trait (see <a href=\"#tbl-5\" class=\"quarto-xref\" aria-expanded=\"false\">Table A1</a>).[2] For each of the three questionnaires, two versions were created – one with a 6-point scale combining verbal endpoints (“does not apply” to “applies”, only endpoints were labeled) with full numeric anchoring (numbers from 1 to 6) and one with a 2-point scale combining verbal labels (“does not apply” and “applies”) with numeric anchors (numbers 0 and 1).\n",
    "\n",
    "## Statistical Analysis\n",
    "\n",
    "All analyses were conducted in R version 4.5.1 (2025-06-13). A full list of software versions can be found in <a href=\"#apx-3\" class=\"quarto-xref\" aria-expanded=\"false\">Appendix C</a>. The data were analyzed using confirmatory factor analyses using the package *lavaan* ([Rosseel, 2012](#ref-R-lavaan)). We used the weighted least squares, mean and variance adjusted (WLSMV) estimator, treating the questionnaire items as ordinal and the self-reported physical gold-standard items body height, body weight, and age as continuous variables. First, we specified (1) unidimensional models without any error correlations, and (2) models with one latent variable and correlated errors. In both models the gold-standard items and the other 12 items were specified as indicators of a single latent variable. Second, to test whether there is a latent variable while controlling for the gold-standard item and gender, (3) models were specified with a single latent variable where the questionnaire items were additionally predicted by the gold-standard item and gender. Third, to compare the correlations between the latent variables with the correlations between the gold-standard items, (4) full three factor models without correlated errors were estimated, in which only the questionnaire items load on their respective latent variable and correlations are estimated between the latent variables, between the gold-standard items, and between the latent variables and the gold-standard items. We also conducted reliability analyses using the package *MBESS* ([Kelley, 2023](#ref-R-MBESS)) and report McDonald’s Omega as a reliability estimate of internal consistency for each scale.\n",
    "\n",
    "## Sample\n",
    "\n",
    "The total sample of our main study consisted of 1854 participants aged between 18 and 97 years (*M* = 32.70, *SD* = 16.01), including 1036 women (56%) and 818 men (44%). The overall sample consisted of two independent subsamples, which were divided into the 2-point and 6-point response format conditions.\n",
    "\n",
    "Participants were recruited in trains, colleges, universities, adult education centers, fitness studios and various public places in Germany and Austria in November and December 2017. Participation was voluntary and without reimbursement. Each participant was handed a paper and pencil questionnaire, alternating between the 2-point and 6-point response scale versions. When a participant handed back the questionnaire, the facilitator immediately checked for missing values, in which case the participant was politely asked to complete the missing questions. With this procedure, we achieved complete responses for all questionnaires.\n",
    "\n",
    "<a href=\"#tbl-1\" class=\"quarto-xref\" aria-expanded=\"false\">Table 1</a> shows the distribution of gender, level of education, native language, and age within the two conditions. As expected based on the randomization procedure, the two subsamples are very similar. Due to the left-skewed age distribution and outlier values, the median is reported as a measure of the central tendency instead of the mean.\n",
    "\n",
    "[1] The data presented in this manuscript has previously been analyzed in the German dissertation thesis of the first author ([Eichhorn, 2019](#ref-eichhornItem2019)). As part of the dissertation, a preregistration was published at <https://osf.io/cz3uv/?view_only=9cac02db231b48629fea9ae53c3038b9> that differs from the analyses reported in the current publication. The results of the preregistered analyses are reported in Eichhorn ([2019](#ref-eichhornItem2019)).\n",
    "\n",
    "[2] Compared to the pilot test, one height and one weight item were slightly reworded to simplify the wording and reduce similarities with other items in the scale."
   ],
   "id": "6e343352-01a4-407b-86b4-0865fc0f2354"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "apa-note": "$SD$ = standard deviation; $IQR$ = interquartile range.",
    "disable-apaquarto-processing": false,
    "ft.align": "left",
    "prefix": "",
    "tblnum": 1
   },
   "outputs": [],
   "source": [
    "results$table1"
   ],
   "id": "dff4b9d8-e1d8-4b97-b12c-4b38fd56365b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*. $SD$ = standard deviation; $IQR$ = interquartile range.\n",
    "\n",
    "  \n",
    "\n",
    "# Results\n",
    "\n",
    "## *Assumption 1:* The self-reported physical body height, weight, and age should have the highest loadings on their latent variables.\n",
    "\n",
    "<a href=\"#tbl-2\" class=\"quarto-xref\" aria-expanded=\"false\">Table 2</a> displays the measurement models for the three scales for body height, body weight, and age for two and six response categories each."
   ],
   "id": "1cc20f58-2ca3-4e68-84a9-c4dc52544e42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "apa-note": "CFI = Comparative Fit Index (scaled); RMSEA = Root Mean Squared Error of Approximation (scaled); SRMR = Standardized Root Mean Residual. Scaled $\\chi^2$, scaled $df$ (degrees of freedom), and scaled *p* values are reported. Correlations with the latent variable higher as the self-reported physical item are printed in bold. The standardized item loadings for the self-reported physical items are presented in a grey shaded box.",
    "disable-apaquarto-processing": false,
    "ft.align": "left",
    "prefix": "",
    "tblnum": 2
   },
   "outputs": [],
   "source": [
    "results$table2"
   ],
   "id": "c8a66b7a-ef06-4d33-9132-57a5e0c6e308"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*. CFI = Comparative Fit Index (scaled); RMSEA = Root Mean Squared Error of Approximation (scaled); SRMR = Standardized Root Mean Residual. Scaled $\\chi^2$, scaled $df$ (degrees of freedom), and scaled *p* values are reported. Correlations with the latent variable higher as the self-reported physical item are printed in bold. The standardized item loadings for the self-reported physical items are presented in a grey shaded box.\n",
    "\n",
    "  \n",
    "\n",
    "Overall, both response formats produced similar loading patterns, but those with two response categories obtained slightly higher loadings compared to six response categories for most items. Questionnaires with two response categories showed slightly better fit indices than those with six categories. All model fits were within the expected range for psychological questionnaires ([Goretzko et al., 2024](#ref-goretzkoEvaluatingModelFit2024)). In particular, the fit indices for the questionnaires on body height and weight with two response categories showed the best fit."
   ],
   "id": "ed89edd2-0d48-4d15-baf6-8bb7cdd719c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher_load <- results$load_df_nomod |> group_by(measure, categories) |>\n",
    "  reframe(freq = sum(head(abs(est.std), 12) > tail(abs(est.std), 1)))"
   ],
   "id": "c0321933-e90f-49fb-b0a4-60ad3fd58a73"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the body height scales, the self-reported physical height loaded higher or similarly high on the latent variables compared to the questionnaire items. However, this pattern slightly differed for the weight and age scales, where several items loaded substantially higher on the latent variable than the physical items: For weight, the items 4 (“I am obese.”) and 5 (“I weigh a lot.”) had especially high loadings on the latent variable for the questionnaires with two and six response categories. For age, item 7 (“I have already lived most of my life.”) had especially high loadings on the latent variable for the questionnaires with two and six response categories. The item loadings for the weight and age scales suggest that the gold-standard items were not essential for measuring the latent variable."
   ],
   "id": "fc69bd35-f7f6-458a-8d5a-5666069b0eb0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of loadings between cfa models with and without correlated errors\n",
    "r_loadings <- cor.test(\n",
    "  # use absolute values because the items were not recoded for cfa models\n",
    "  abs(results$load_df_nomod$est.std), abs(results_secondary$load_df_mod$est.std), \n",
    "  method = \"pearson\")\n",
    "r_loadings <- apa_print(r_loadings)$table"
   ],
   "id": "1d74cd3d-b502-4632-a77f-d078291fee82"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after allowing for correlated errors as suggested by standard modification indices, the loading patterns did not improve (see <a href=\"#tbl-5\" class=\"quarto-xref\" aria-expanded=\"false\">Table A1</a>). Loading patterns with and without modifications were correlated at .98 (*p* \\< .001) across all questionnaires (body height, body weight, age) and response variants (two and six categories).\n",
    "\n",
    "## *Assumption 2:* The measurement should have a psychological component, and the item responses cannot be fully explained by the self-reported physical measurement and gender. A systemic residual should remain when corrected for self-reported physical height and gender.\n",
    "\n",
    "<a href=\"#tbl-3\" class=\"quarto-xref\" aria-expanded=\"false\">Table 3</a> displays item loadings on the latent variable when controlling for the self-reported physical item and self-reported gender."
   ],
   "id": "eabe472b-7bcc-457b-a2e0-0b296970c415"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "apa-note": "Standardized regression weights greater than .60 in absolute values are printed in bold. Latent = standardized item loading on the respective latent variable (height, weight or age); Physical = standardized regression weight, predicting the item response by the respective self-reported physical measures (height, weight or age); Gender = standardized regression weight, predicting the item response by the self-reported gender.",
    "disable-apaquarto-processing": false,
    "ft.align": "left",
    "prefix": "",
    "tblnum": 3
   },
   "outputs": [],
   "source": [
    "results$table3"
   ],
   "id": "b68d52b9-c62a-41aa-b16e-7eb915b99153"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*. Standardized regression weights greater than .60 in absolute values are printed in bold. Latent = standardized item loading on the respective latent variable (height, weight or age); Physical = standardized regression weight, predicting the item response by the respective self-reported physical measures (height, weight or age); Gender = standardized regression weight, predicting the item response by the self-reported gender.\n",
    "\n",
    "  \n",
    "\n",
    "For body height, we obtained low item loadings on the latent variable but high regression weights with the gold-standard item of physical body height. In particular, the third item (“Chairs and tables are usually too low for me.”) exhibited the highest loading on the latent variable for both response formats. In contrast, item 11 (“I have to stand at the front of group photos so that I can be seen clearly.”) and item 12 (“When I hug other people in greeting, I have to bend downwards.”) were best predicted by the self-reported physical body height for both response formats.[1] This pattern does not convincingly confirm the existence of a psychological latent height variable after controlling for the self-reported physical item and gender.\n",
    "\n",
    "For body weight, the items with high loadings on the latent variable also exhibited high associations with the self-reported physical body weight. Item 4 (“I am obese.”) had the highest loading on the latent variable for both response formats. Item 5 (“I weigh a lot.”) was explained best by the self-reported physical body weight. Item 9 (“I have a lot of space between the armrests in airplane seats.”) had a low loading on the latent variable but was moderately predicted by the self-reported physical body weight for both response formats. Notably, item 11 (“If I have the choice between the elevator and the stairs, I take the elevator.”) was not related to either the self-reported physical item or the latent variable for both response formats, indicating that it may represent a more health-related perspective. Taken together, the resulting latent weight variable is hard to interpret.\n",
    "\n",
    "For age, we observed the biggest discrepancy between items with high loadings on the latent variable and items best predicted by self-reported physical age. Item 3 (“I have a lot of life experience.”) and item 9 (“I have years of work experience.”) did not load on the latent variable after controlling for physical age and gender but were predicted by self-reported physical age for both response formats. In contrast, the three items most prototypical of the latent variable were item 2 (“Over time, my mental capacity has decreased.”), item 5 (“Over time, my memory has deteriorated.”), and item 4 (“Over time, my ability to react has decreased.”) for both response formats. Thus, the latent variable might be interpreted as mental age, but not all items have a substantial loading on this general factor.\n",
    "\n",
    "When looking at self-reported gender, there are moderate standardized regression weights for some items of body height (e.g., item 8 “Pants are often so short for me.”) and body weight (e.g., item 6 “I need to lose weight.”). These items may cause problems when applied to both men and women (differential item functioning; see [Hilbert et al., 2022](#ref-hilbertWhatMeasureEmpirical2022), for a comparable case). Notably, there are only non-significant low standardized regression weights of self-reported gender predicting age items.\n",
    "\n",
    "## Assumption 3a, b: The correlational pattern between the latent variables for the construct should correspond to the correlations of the self-reported gold-standard items and the validity should be higher for the 6-point response categories compared to the 2-point response categories.\n",
    "\n",
    "As depicted in <a href=\"#tbl-4\" class=\"quarto-xref\" aria-expanded=\"false\">Table 4</a>, the correlations between the latent variables do not match those between the self-reported physical items. While height and age showed relatively similar low correlations, the physical correlations of weight and age were overestimated by the correlations between the latent variables and the physical correlations between height and weight were underestimated. Most notably, correlations did not differ substantially between the questionnaires with two and with six response categories. Descriptively, the physical correlations seemed to be reproduced by the latent correlations slightly better for the two response categories. However, reliability estimates (Omega) were lower for two response categories compared to six response categories.\n",
    "\n",
    "[1] Note that although the models for height (controlling for the physical item and gender) estimated some absolute standardized loadings greater than 1, all models converged and the diagnostics used by the *lavaan* package ([Rosseel, 2012](#ref-R-lavaan)) did not report any problems."
   ],
   "id": "e6346c4f-f5b7-46fd-8aa9-040d98690a44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "apa-note": "Correlations between the latent variables are shown above the diagonal (printed in bold) and correlations between the self-reported physical measures are shown below the diagonal. The correlations were taken out of a latent variable model (one for two and one for six response categories) including all self-reported physical items and all latent variables with the allocated items. The models showed the following fit: scaled chi-square (six response categories) = 6,203.19, $df$ = 696, $p$ < .001, scaled CFI = .85, scaled RMSEA = .09, SRMR = .11; scaled chi-square (two response categories) = 3,440.02, $df$ = 696, $p$ < .001, scaled CFI = .86, scaled RMSEA = .07, SRMR = .12. In the diagonal (grey shaded boxes) the reliability estimates Omega for the scales can be found. * $p \\leq$ .05, ** $p \\leq$ .01, *** $p \\leq$ .001.",
    "ft.align": "left",
    "prefix": "",
    "tblnum": 4
   },
   "outputs": [],
   "source": [
    "results$table4"
   ],
   "id": "b6c2508f-d952-4228-b9a9-5628add96494"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*. Correlations between the latent variables are shown above the diagonal (printed in bold) and correlations between the self-reported physical measures are shown below the diagonal. The correlations were taken out of a latent variable model (one for two and one for six response categories) including all self-reported physical items and all latent variables with the allocated items. The models showed the following fit: scaled chi-square (six response categories) = 6,203.19, $df$ = 696, $p$ \\< .001, scaled CFI = .85, scaled RMSEA = .09, SRMR = .11; scaled chi-square (two response categories) = 3,440.02, $df$ = 696, $p$ \\< .001, scaled CFI = .86, scaled RMSEA = .07, SRMR = .12. In the diagonal (grey shaded boxes) the reliability estimates Omega for the scales can be found. \\* $p \\leq$ .05, \\*\\* $p \\leq$ .01, \\*\\*\\* $p \\leq$ .001.\n",
    "\n",
    "  \n",
    "\n",
    "# Discussion\n",
    "\n",
    "## Summary\n",
    "\n",
    "The goal of this study was to find out whether gold-standard items have the highest loadings on the corresponding latent variable. This was investigated using items with two and six response categories which measure these physical traits. The results reveal that this is only an exception, and two response categories perform not necessarily worse than six response categories regarding validity and reliability. Gold-standard items might help to ensure the interpretation of the latent variable. The choice of the response format should be based on empirical testing and extensive cognitive interviews. It seems not sufficient to take advice from the literature on how to choose the number of response categories to optimize reliability. The benefit of gold-standard items will be discussed in the following sections.\n",
    "\n",
    "## Gold-Standard Items\n",
    "\n",
    "Gold-standard items did not work as theoretically expected in this study. However, we still believe they are important. Only the gold-standard item for body height – for six, not for two response categories – had the highest loading on the latent variable. Bortolotti et al. ([2013](#ref-bortolottiRelevanceAdvantagesUsing2013)), who previously applied the same procedure with two response categories to investigate a gold-standard item for body height, found a correlation of .86 with body height. This correlation pretty much matches our correlation with the latent variable. The correlation was slightly higher for our 2-response category scale (.87) compared to our 6-response category scale (.86), but there were also items which had descriptively equal or higher correlations (biserial correlations) with the sum score than the self-reported physical item (Pearson correlation). This might be because we reported a latent correlation corrected for disattenuation, and our scale had 12 instead of 27 items. Nevertheless, our results depict a conceptual replication of Bortolotti et al. ([2013](#ref-bortolottiRelevanceAdvantagesUsing2013)) with a different questionnaire.\n",
    "\n",
    "The results differed for the other latent variables of body weight and age, which exhibited lower correlations between the latent variable and their gold-standard items. This seems problematic as these items were designed to be the “gold” measure of the latent variable and should ensure a consistent interpretation. Thus, we should carefully reflect what this finding means for item construction for psychological scales of non-physical traits. If this basic requirement is not met, even for traits that seem rather straightforward to measure, what about more complex constructs? To avoid a misleading interpretation of a latent variable, it might be very helpful to formulate a priori hypotheses about the importance of the constructed items as we did here to test the construct validity of a test. If we, for example, want to measure *interpersonal warmth* as a big five facet and construct items that describe this facet, an item that most directly measures warmth should have its highest loading on the latent variable, otherwise the interpretation of the latent variable is not justified.\n",
    "\n",
    "We must be aware, that general model fit does not prove how well items are formulated (see [Pargent et al., 2019](#ref-pargentCanMakeIt2019)). Model fit also does not reveal if the applied items are helpful to measure the latent variable. Model fit simply compares a model implied variance/covariance matrix with an empirical variance/covariance matrix. In this study, the a priori most suitable items did not have always the highest discrimination parameters or loadings. Thus, simply selecting items according to their loadings and letting the factor analysis decide which item is good or not is probably insufficient. There must be an item content loading fit.\n",
    "\n",
    "The reliability estimate of the questionnaire informs us only about the precision of measurement and not whether our measurement is valid. This does not necessarily contradict attempts to choose items based on reliability (e.g., see [Zijlmans et al., 2019](#ref-zijlmansItemScoreReliabilitySelection2019)) since items must have high loadings to achieve high reliability estimates for the scale.\n",
    "\n",
    "Thus, we suggest using gold-standard items as described above. It should be noted, however, that it is critical not to implement the gold-standard item in the final scale since we would then create a part-whole relationship. This no desirable situation since all test models (classical and IRT models) assume that the probability of a positive response of a person to an item should not depend on this person’s response to any other item ([Debelak & Koller, 2020](#ref-debelakTestingLocalIndependence2020)).\n",
    "\n",
    "## Physical Traits as Psychological Variables\n",
    "\n",
    "Previous hints suggest that measuring physical attributes through psychological questionnaires is not always connected to a psychological latent variable guiding behavior ([Hilbert et al., 2022](#ref-hilbertWhatMeasureEmpirical2022); [Van der Linden, 2016](#ref-vanderlindenUnidimensionalLogisticResponse2016)). Similarly, in our study, it remained unclear if a psychological latent variable beyond body height and weight was measured and how such a latent variable could be interpreted. Only for age there was a latent variable, which can be interpreted as cognitive or psychological age ([Barak & Schiffman, 1981](#ref-barakCognitiveAgeNonchronological1981)). Furthermore, it seems helpful to include additional items, that are not intended to be measured but may further explain the item responses of interest, such as gender or items from the nomological net to reveal possible dependencies and to decide whether these dependencies are in line with the definition of the latent variables.\n",
    "\n",
    "## Number of Categories\n",
    "\n",
    "As expected, reliability estimates were higher for scales with six response categories compared to two categories. The results with regard to model fit and validity, indicated as correlations between latent variables compared to the correlation between gold-standard items, are mixed. Some fit indices suggested slightly better fit for items with two response categories and some for six categories. The same holds true for the differences between the correlations of the gold-standard items and the correlations of the latent variables. Except for reliability, the study revealed no clear picture to choose between two or six response categories. Hilbert et al. ([2016](#ref-hilbertInfluenceResponseFormat2016), [2022](#ref-hilbertWhatMeasureEmpirical2022)) showed that the same items with a different number of response categories do not measure the same latent variable. This result highlights that the choice of the number of response categories constructing a questionnaire should be based on an empirical study comparing several options accompanied by an intensive cognitive pretesting phase and not only based on the literature which focuses on maximal reliability.\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "The results presented here should prompt reflection and reconsideration of standard procedures of item construction in psychology. First, it may be helpful to more strongly consider content validity when developing items. Items that either represent a kind of gold-standard with specific hypotheses about the ranking of the loadings or construct-divergent items that (in)validate the items intended to measure a latent variable should be included in the construction process. Revisiting the example of *interpersonal warmth* as a personality facet, such additional validation items could, for example, measure warmth itself or openness. An openness scale or marker items that show high correlations with these warmth items should not be included in the final scale but only used for validation purposes. These demands are not entirely new, but should be newly emphasized based on the results of our analyses, calling for more stringent item construction approaches. Second, the choice of an optimal response scale may not be as clear-cut as previously suggested (e.g., [Lee & Paek, 2014](#ref-leeSearchOptimalNumber2014)). We found that items with two response categories were not per se unfavorable, as often suggested in the literature. While our binary scales obtained lower reliability estimates as expected (see [Preston & Colman, 2000](#ref-prestonOptimalNumberResponse2000); [Revilla et al., 2014](#ref-revillaChoosingNumberCategories2014)), other results regarding validity and model fit were mixed. Since reliability is easier to control for by adding more suitable items, construct validity seems to be the stronger argument when choosing the number of response categories. In sum, we believe that decisions on response scales should be empirically founded, especially in high stakes situations (e.g., clinical diagnosis or personnel selection), comparing alternative numbers of response categories in pilot testing. In this context, it is important to recognize that the number of response categories can influence what latent variables are measured (see [Hilbert et al., 2016](#ref-hilbertInfluenceResponseFormat2016), [2022](#ref-hilbertWhatMeasureEmpirical2022)). Thus, comparing the construct validity of questionnaires differing in the number of response categories is essential. Nevertheless, it remains necessary to subject response scales to intensive cognitive pretesting to determine a suitable number of categories. On the one hand, cognitive interviews can reveal when single categories are systematically overlooked by respondents lacking information or cognitive capacity to differentiate categories. On the other hand, cognitive pretests help assess participants’ cognitive load, which should always be kept in mind. For example, two-point scales, which are commonly criticized, have previously been shown to require less effort from the respondents ([Hilbert et al., 2016](#ref-hilbertInfluenceResponseFormat2016)).\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Based on the results of the present study, we advocate the inclusion of gold-standard items, i.e. items that are supposed to measure the intended construct most directly, to check the interpretation of latent variables in the construction of psychological questionnaires. In addition, for questionnaires that are used to make particularly important decisions, we recommend empirically testing the choice of response format, considering both validity and reliability to make a well-founded decision. The pre-selection of response formats should include cognitive pretests of the items.\n",
    "\n",
    "  \n",
    "\n",
    "# References\n",
    "\n",
    "Allaire, J. J., Teague, C., Scheidegger, C., Xie, Y., Dervieux, C., & Woodhull, G. (2025). *Quarto* (Version 1.7) \\[Computer software\\]. <https://doi.org/10.5281/zenodo.5960048>\n",
    "\n",
    "Aust, F., & Barth, M. (2024). *<span class=\"nocase\">papaja</span>: Prepare reproducible APA journal articles with R Markdown*. <https://doi.org/10.32614/CRAN.package.papaja>\n",
    "\n",
    "Barak, B., & Schiffman, L. G. (1981). Cognitive age: A nonchronological age variable. *Advances in Consumer Research*, *8*(1), 602–606.\n",
    "\n",
    "Barth, M. (2025). *<span class=\"nocase\">tinylabels</span>: Lightweight variable labels*. <https://doi.org/10.32614/CRAN.package.tinylabels>\n",
    "\n",
    "Bortolotti, S. L. V., Tezza, R., De Andrade, D. F., Bornia, A. C., & De Sousa Júnior, A. F. (2013). Relevance and advantages of using the item response theory. *Quality & Quantity*, *47*(4), 2341–2360. <https://doi.org/10.1007/s11135-012-9684-5>\n",
    "\n",
    "Bradley, K. D., Peabody, M. R., Akers, K. S., & Knutson, N. M. (2015). Rating Scales in Survey Research: Using the Rasch model to illustrate the middle category measurement flaw. *Survey Practice*, *8*(1), 1–12. <https://doi.org/10.29115/SP-2015-0001>\n",
    "\n",
    "Broughton, R. (1984). A prototype strategy for construction of personality scales. *Journal of Personality and Social Psychology*, *47*(6), 1334–1346. <https://doi.org/10.1037/0022-3514.47.6.1334>\n",
    "\n",
    "Burisch, M. (1984). Approaches to personality inventory construction: A comparison of merits. *American Psychologist*, *39*(3), 214–227. <https://doi.org/10.1037/0003-066X.39.3.214>\n",
    "\n",
    "Conigrave, J. (2023). *Corx: Create and format correlation matrices*. <https://CRAN.R-project.org/package=corx>\n",
    "\n",
    "Debelak, R., & Koller, I. (2020). Testing the Local Independence Assumption of the Rasch Model With *Q*<sub>3</sub> -Based Nonparametric Model Tests. *Applied Psychological Measurement*, *44*(2), 103–117. <https://doi.org/10.1177/0146621619835501>\n",
    "\n",
    "Eichhorn, K. (2019). *Item und skala: Empirische untersuchungen zur gültigkeit psychologischer messungen anhand physikalischer merkmale* \\[Ludwig-Maximilians-Universität München\\]. <http://nbn-resolving.de/urn:nbn:de:bvb:19-236286>\n",
    "\n",
    "Faulbaum, F., Prüfer, P., & Rexroth, M. (2009). *Was ist eine gute Frage?* VS Verlag für Sozialwissenschaften. <https://doi.org/10.1007/978-3-531-91441-1>\n",
    "\n",
    "Gohel, D., & Skintzos, P. (2024). *Flextable: Functions for tabular reporting*. <https://CRAN.R-project.org/package=flextable>\n",
    "\n",
    "Goretzko, D., Siemund, K., & Sterner, P. (2024). Evaluating Model Fit of Measurement Models in Confirmatory Factor Analysis. *Educational and Psychological Measurement*, *84*(1), 123–144. <https://doi.org/10.1177/00131644231163813>\n",
    "\n",
    "Grolemund, G., & Wickham, H. (2011). Dates and times made easy with <span class=\"nocase\">lubridate</span>. *Journal of Statistical Software*, *40*(3), 1–25. <https://www.jstatsoft.org/v40/i03/>\n",
    "\n",
    "Hilbert, S., Küchenhoff, H., Sarubin, N., Toyo Nakagawa, T., & Bühner, M. (2016). The influence of the response format in a personality questionnaire: An analysis of a dichotomous, a <span class=\"nocase\">Likert-type</span>, and a visual analogue scale. *TPM - Testing, Psychometrics, Methodology in Applied Psychology*, *23*(1), 3–24. <https://doi.org/10.4473/TPM23.1.1>\n",
    "\n",
    "Hilbert, S., Pargent, F., Kraus, E., Naumann, F., Eichhorn, K., Ungar, P., & Bühner, M. (2022). What’s the measure? An empirical investigation of self-ratings on response scales. *International Journal of Social Research Methodology*, *25*(1), 59–78. <https://doi.org/10.1080/13645579.2020.1839163>\n",
    "\n",
    "Holt, J. C. ten, Duijn, M. A. J. van, & Boomsma, A. (2010). Scale construction and evaluation in practice: A review of factor analysis versus item response theory applications. *Psychological Test and Assessment Modeling*, *52*(3), 272–297.\n",
    "\n",
    "Jorgensen, T. D., Pornprasertmanit, S., Schoemann, A. M., & Rosseel, Y. (2025). *`semTools`: Useful tools for structural equation modeling*. <https://CRAN.R-project.org/package=semTools>\n",
    "\n",
    "Kelley, K. (2023). *MBESS: The MBESS r package*. <https://CRAN.R-project.org/package=MBESS>\n",
    "\n",
    "Lee, J., & Paek, I. (2014). In Search of the Optimal Number of Response Categories in a Rating Scale. *Journal of Psychoeducational Assessment*, *32*(7), 663–673. <https://doi.org/10.1177/0734282914522200>\n",
    "\n",
    "Lord, F. M., Novick, M. R., Birnbaum, A., & Lord, F. M. (1968). *Statistical theories of mental test scores* (2. print). Addison-Wesley.\n",
    "\n",
    "Martin, R. (1929). *Anthropometrie: Anleitung Zu Selbständigen Anthropologischen Erhebungen* (2nd ed). Springer Berlin / Heidelberg.\n",
    "\n",
    "Masuda, S., Sakagami, T., Kawabata, H., Kijima, N., & Hoshino, T. (2017). Respondents with low motivation tend to choose middle category: Survey questions on happiness in Japan. *Behaviormetrika*, *44*(2), 593–605. <https://doi.org/10.1007/s41237-017-0026-8>\n",
    "\n",
    "Maul, A. (2017). Rethinking traditional methods of survey validation. *Measurement: Interdisciplinary Research and Perspectives*, *15*(2), 51–69. <https://doi.org/10.1080/15366367.2017.1348108>\n",
    "\n",
    "McCreary, D. (2002). Gender and Age Differences in the Relationship Between Body Mass Index and Perceived Weight: Exploring the Paradox. *International Journal of Men’s Health*, *1*(1), 31–42. <https://doi.org/10.3149/jmh.0101.31>\n",
    "\n",
    "McNeish, D., An, J., & Hancock, G. R. (2018). The Thorny Relation Between Measurement Quality and Fit Index Cutoffs in Latent Variable Models. *Journal of Personality Assessment*, *100*(1), 43–52. <https://doi.org/10.1080/00223891.2017.1281286>\n",
    "\n",
    "Montepare, J. M., & Lachman, M. E. (1989). \"You’re only as old as you feel\": <span class=\"nocase\">Self-perceptions</span> of age, fears of aging, and life satisfaction from adolescence to old age. *Psychology and Aging*, *4*(1), 73–78. <https://doi.org/10.1037/0882-7974.4.1.73>\n",
    "\n",
    "Müller, K., & Wickham, H. (2023). *Tibble: Simple data frames*. <https://tibble.tidyverse.org/>\n",
    "\n",
    "Pargent, F., Hilbert, S., Eichhorn, K., & Bühner, M. (2019). Can’t Make it Better nor Worse: An Empirical Study About the Effectiveness of General Rules of Item Construction on Psychometric Properties. *European Journal of Psychological Assessment*, *35*(6), 891–899. <https://doi.org/10.1027/1015-5759/a000471>\n",
    "\n",
    "Posit team. (2025). *RStudio: Integrated development environment for r*. Posit Software, PBC. <http://www.posit.co/>\n",
    "\n",
    "Preston, C. C., & Colman, A. M. (2000). Optimal number of response categories in rating scales: Reliability, validity, discriminating power, and respondent preferences. *Acta Psychologica*, *104*(1), 1–15. <https://doi.org/10.1016/S0001-6918(99)00050-5>\n",
    "\n",
    "Prüfer, P., & Rexroth, M. (1996). *Verfahren zur evaluation von survey-fragen: Ein überblick* (Vol. 1996/05, p. 34). Zentrum für Umfragen, Methoden und Analysen -ZUMA-.\n",
    "\n",
    "Prüfer, P., & Rexroth, M. (2005). *Kognitive interviews* (Vol. 15, p. 26). Zentrum für Umfragen, Methoden und Analysen -ZUMA-.\n",
    "\n",
    "R Core Team. (2025a). *Foreign: Read data stored by ’minitab’, ’s’, ’SAS’, ’SPSS’, ’stata’, ’systat’, ’weka’, ’dBase’, ...* <https://CRAN.R-project.org/package=foreign>\n",
    "\n",
    "R Core Team. (2025b). *R: A language and environment for statistical computing*. R Foundation for Statistical Computing. <https://www.R-project.org/>\n",
    "\n",
    "Revilla, M. A., Saris, W. E., & Krosnick, J. A. (2014). Choosing the Number of Categories in Agree–Disagree Scales. *Sociological Methods & Research*, *43*(1), 73–97. <https://doi.org/10.1177/0049124113509605>\n",
    "\n",
    "Rosseel, Y. (2012). <span class=\"nocase\">lavaan</span>: An R package for structural equation modeling. *Journal of Statistical Software*, *48*(2), 1–36. <https://doi.org/10.18637/jss.v048.i02>\n",
    "\n",
    "Schneider, W. J. (2025). *<span class=\"nocase\">apaquarto</span>* \\[Computer software\\]. <https://github.com/wjschne/apaquarto>\n",
    "\n",
    "Schwall, A. R. (2012). *Defining Age and Using Age-Relevant Constructs*. Oxford University Press. <https://doi.org/10.1093/oxfordhb/9780195385052.013.0080>\n",
    "\n",
    "Van der Linden, W. J. (2016). Unidimensional logistic response models. In W. J. Van der Linden (Ed.), *Handbook of item response theory, volume one: models* (pp. 13–30). Chapman & Hall/CRC. <https://doi.org/10.1201/9781315374512>\n",
    "\n",
    "Weijters, B., Cabooter, E., & Schillewaert, N. (2010). The effect of rating scale format on response styles: The number of response categories and response category labels. *International Journal of Research in Marketing*, *27*(3), 236–247. <https://doi.org/10.1016/j.ijresmar.2010.02.004>\n",
    "\n",
    "Wickham, H. (2016). *ggplot2: Elegant graphics for data analysis*. Springer-Verlag New York. <https://ggplot2.tidyverse.org>\n",
    "\n",
    "Wickham, H. (2023a). *Forcats: Tools for working with categorical variables (factors)*. <https://forcats.tidyverse.org/>\n",
    "\n",
    "Wickham, H. (2023b). *Stringr: Simple, consistent wrappers for common string operations*. <https://stringr.tidyverse.org>\n",
    "\n",
    "Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the <span class=\"nocase\">tidyverse</span>. *Journal of Open Source Software*, *4*(43), 1686. <https://doi.org/10.21105/joss.01686>\n",
    "\n",
    "Wickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). *Dplyr: A grammar of data manipulation*. <https://dplyr.tidyverse.org>\n",
    "\n",
    "Wickham, H., & Henry, L. (2025). *Purrr: Functional programming tools*. <https://CRAN.R-project.org/package=purrr>\n",
    "\n",
    "Wickham, H., Hester, J., & Bryan, J. (2024). *Readr: Read rectangular text data*. <https://readr.tidyverse.org>\n",
    "\n",
    "Wickham, H., Vaughan, D., & Girlich, M. (2024). *Tidyr: Tidy messy data*. <https://tidyr.tidyverse.org>\n",
    "\n",
    "William Revelle. (2025). *Psych: Procedures for psychological, psychometric, and personality research*. Northwestern University. <https://CRAN.R-project.org/package=psych>\n",
    "\n",
    "Willis, G. (2005). *Cognitive Interviewing*. SAGE Publications, Inc. <https://doi.org/10.4135/9781412983655>\n",
    "\n",
    "Zijlmans, E. A. O., Tijmstra, J., Van Der Ark, L. A., & Sijtsma, K. (2019). Item-Score Reliability as a Selection Tool in Test Construction. *Frontiers in Psychology*, *9*, 2298. <https://doi.org/10.3389/fpsyg.2018.02298>\n",
    "\n",
    "# Appendix A\n",
    "\n",
    "# CFA models with correlated errors"
   ],
   "id": "d7420048-9fe4-43cf-8b64-9d93924cf372"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_H10_H11_6 <- results_secondary$cor_errors |>\n",
    "  filter(lhs == \"KGr_22\" & rhs == \"KGr_23\" & categories == 6) |>\n",
    "  pull(est.std)\n",
    "r_H10_H11_2 <- results_secondary$cor_errors |>\n",
    "  filter(lhs == \"KGr_22\" & rhs == \"KGr_23\" & categories == 2) |>\n",
    "  pull(est.std)\n",
    "\n",
    "r_H4_H9_6 <- results_secondary$cor_errors |>\n",
    "  filter(lhs == \"KGr_16\" & rhs == \"KGr_21\" & categories == 6) |>\n",
    "  pull(est.std)\n",
    "r_H4_H9_2 <- results_secondary$cor_errors |>\n",
    "  filter(lhs == \"KGr_16\" & rhs == \"KGr_21\" & categories == 2) |>\n",
    "  pull(est.std)\n",
    "\n",
    "r_W6_W12_6 <- results_secondary$cor_errors |>\n",
    "  filter(lhs == \"KGe_30\" & rhs == \"KGe_36\" & categories == 6) |>\n",
    "  pull(est.std)\n",
    "r_W6_W12_2 <- results_secondary$cor_errors |>\n",
    "  filter(lhs == \"KGe_30\" & rhs == \"KGe_36\" & categories == 2) |>\n",
    "  pull(est.std)\n",
    "\n",
    "r_W3_W7_6 <- results_secondary$cor_errors |>\n",
    "  filter(lhs == \"KGe_27\" & rhs == \"KGe_31\" & categories == 6) |>\n",
    "  pull(est.std)\n",
    "r_W3_W7_2 <- results_secondary$cor_errors |>\n",
    "  filter(lhs == \"KGe_27\" & rhs == \"KGe_31\" & categories == 2) |>\n",
    "  pull(est.std)\n",
    "\n",
    "r_A3_A9_6 <- results_secondary$cor_errors |>\n",
    "  filter(lhs == \"A_3\" & rhs == \"A_9\" & categories == 6) |>\n",
    "  pull(est.std)\n",
    "r_A3_A9_2 <- results_secondary$cor_errors |>\n",
    "  filter(lhs == \"A_3\" & rhs == \"A_9\" & categories == 2) |>\n",
    "  pull(est.std)\n",
    "\n",
    "r_A2_A5_6 <- results_secondary$cor_errors |>\n",
    "  filter(lhs == \"A_2\" & rhs == \"A_5\" & categories == 6) |>\n",
    "  pull(est.std)\n",
    "r_A2_A5_2 <- results_secondary$cor_errors |>\n",
    "  filter(lhs == \"A_2\" & rhs == \"A_5\" & categories == 2) |>\n",
    "  pull(est.std)\n",
    "\n",
    "r_A7_A10_6 <- results_secondary$cor_errors |>\n",
    "  filter(lhs == \"A_7\" & rhs == \"A_10\" & categories == 6) |>\n",
    "  pull(est.std)\n",
    "r_A7_A10_2 <- results_secondary$cor_errors |>\n",
    "  filter(lhs == \"A_7\" & rhs == \"A_10\" & categories == 2) |>\n",
    "  pull(est.std)"
   ],
   "id": "31fcec9d-7c84-4d75-8d3f-117c07b21d3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "apa-note": "CFI = Comparative Fit Index (scaled). RMSEA = Root Mean Squared Error of Approximation (scaled). SRMR = Standardized Root Mean Residual. Scaled chi-square, scaled $df$ (degrees of freedom), and scaled $p$ values are reported. Correlations with the latent variable higher as the self-reported physical item are printed in bold. The standardized item loadings for the self-reported physical items are presented in a grey shaded box.The following correlated errors were specified according to high modification indices and good interpretability (parenthesis error correlations for two and six response categories): \"I have to look up when I talk to other people.\" (H10) and \"I have to stand at the front of group photos so that I can be seen clearly.\" (H11) (0.57, 0.44); \"In the supermarket, I can reach the things on the top shelf without any problems.\" (H4) and \"I need a chair if I want to get things from the top shelf.\" (H9) (-0.51, -0.40); \"I need to lose weight.\" (W6) and \"I should eat less.\" (W12) (0.71, 0.55); \"I have a wide waistband when it comes to pants.\" (W3) and \"My pants have a small waistband.\" (W7) (-0.55, -0.33); \"Over time, my mental capacity has decreased.\" (A3) and \"I have years of work experience.\" (A9) (0.53, 0.49); \"Over time, my mental capacity has decreased.\" (A2) and \"Over time, my memory has deteriorated.\" (A5) (0.62, 0.40); \"I have already lived most of my life.\" (A7) and \"My whole life still lies ahead of me.\" (A10) (-0.41, -0.48).",
    "disable-apaquarto-processing": false,
    "ft.align": "left",
    "prefix": "A",
    "tblnum": 1
   },
   "outputs": [],
   "source": [
    "results_secondary$table5"
   ],
   "id": "bd923379-85f9-41d7-a411-30110cd6322d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*. CFI = Comparative Fit Index (scaled). RMSEA = Root Mean Squared Error of Approximation (scaled). SRMR = Standardized Root Mean Residual. Scaled chi-square, scaled $df$ (degrees of freedom), and scaled $p$ values are reported. Correlations with the latent variable higher as the self-reported physical item are printed in bold. The standardized item loadings for the self-reported physical items are presented in a grey shaded box.The following correlated errors were specified according to high modification indices and good interpretability (parenthesis error correlations for two and six response categories): “I have to look up when I talk to other people.” (H10) and “I have to stand at the front of group photos so that I can be seen clearly.” (H11) (0.57, 0.44); “In the supermarket, I can reach the things on the top shelf without any problems.” (H4) and “I need a chair if I want to get things from the top shelf.” (H9) (-0.51, -0.40); “I need to lose weight.” (W6) and “I should eat less.” (W12) (0.71, 0.55); “I have a wide waistband when it comes to pants.” (W3) and “My pants have a small waistband.” (W7) (-0.55, -0.33); “Over time, my mental capacity has decreased.” (A3) and “I have years of work experience.” (A9) (0.53, 0.49); “Over time, my mental capacity has decreased.” (A2) and “Over time, my memory has deteriorated.” (A5) (0.62, 0.40); “I have already lived most of my life.” (A7) and “My whole life still lies ahead of me.” (A10) (-0.41, -0.48).\n",
    "\n",
    "# Appendix B\n",
    "\n",
    "# Item translations\n",
    "\n",
    "**Table B2**\n",
    "\n",
    "Translated items used in this study\n",
    "\n",
    "| Item | Item wording (Original wording in German) |\n",
    "|:------------------|:----------------------------------------------------|\n",
    "| **Height 1** | I keep my head down when I walk through doors. (Ich ziehe den Kopf ein wenn ich durch Türen gehe.) |\n",
    "| **Height 2** | In the middle of a crowd, I can see over most other people. (Inmitten einer Menschenmenge kann ich über die meisten anderen Menschen hinwegblicken.) |\n",
    "| **Height 3** | Chairs and tables are usually too low for me. (Stühle und Tische sind meistens zu niedrig für mich.) |\n",
    "| **Height 4** | In the supermarket, I can reach the things on the top shelf without any problems. (Im Supermarkt komme ich ohne Probleme an die Sachen im obersten Regal.) |\n",
    "| **Height 5** | When I drive a car that was previously driven by someone else, I usually have to push the seat backwards. (Wenn ich ein Auto fahre, das vorher jemand anderes gefahren hat, muss ich üblicherweise den Sitz nach hinten schieben.) |\n",
    "| **Height 6** | When I stretch out straight in hotel beds, my feet overlap. (Wenn ich mich in Hotelbetten gerade ausstrecke, dann stehen meine Füße über.) |\n",
    "| **Height 7** | On airplanes, I bump my knees against the seat in front of me. (Im Flugzeug stoße ich mit den Knien am Vordersitz an.) |\n",
    "| **Height 8** | Pants are often too short for me. (Hosen sind mir häufig zu kurz.) |\n",
    "| **Height 9** | I need a chair if I want to get things from the top shelf. (Ich brauche einen Stuhl, wenn ich Sachen aus dem obersten Regal holen möchte.) |\n",
    "| **Height 10** | I have to look up when I talk to other people. (Wenn ich mich mit anderen Menschen unterhalte muss ich nach oben schauen.) |\n",
    "| **Height 11** | I have to stand at the front of group photos so that I can be seen clearly. (Ich muss mich bei Gruppenfotos nach vorne stellen, damit ich gut zu sehen bin.) |\n",
    "| **Height 12** | When I hug other people in greeting, I have to bend downwards. (Wenn ich andere Menschen zur Begrüßung umarme, muss ich mich nach unten beugen.) |\n",
    "| **Weight 1** | I am often afraid that chairs will give way under me. (Ich habe oft Angst, dass Stühle unter mir nachgeben.) |\n",
    "| **Weight 2** | Other people may think that I sit on the sofa in the evening and eat chocolate and potato chips. (Möglicherweise denken andere Menschen von mir, dass ich abends auf dem Sofa sitze und Schokolade und Chips esse.) |\n",
    "| **Weight 3** | I have a wide waistband when it comes to pants. (Bei Hosen habe ich eine große Bundweite.) |\n",
    "| **Weight 4** | I am obese. (Ich bin dick.) |\n",
    "| **Weight 5** | I weigh a lot. (Ich wiege viel.) |\n",
    "| **Weight 6** | I need to lose weight. (Ich müsste abnehmen.) |\n",
    "| **Weight 7** | My pants have a small waistband. (Meine Hosen haben eine kleine Bundweite.) |\n",
    "| **Weight 8** | I am good at squeezing through narrow gaps. (Ich kann mich gut durch enge Spalten quetschen.) |\n",
    "| **Weight 9** | I have a lot of space between the armrests in airplane seats. (Zwischen den Armlehnen in Flugzeugsitzen habe ich viel Platz.) |\n",
    "| **Weight 10** | I take up a lot of space in the elevator. (Im Aufzug nehme ich viel Platz ein.) |\n",
    "| **Weight 11** | If I have the choice between the elevator and the stairs, I take the elevator. (Wenn ich die Wahl habe zwischen Aufzug und Treppe, dann nehme ich den Aufzug.) |\n",
    "| **Weight 12** | I should eat less. (Ich sollte weniger essen.) |\n",
    "| **Age 1** | I have physical ailments. (Ich habe körperliche Gebrechen.) |\n",
    "| **Age 2** | Over time, my mental capacity has decreased. (Im Laufe der Zeit hat meine geistige Leistungsfähigkeit abgenommen.) |\n",
    "| **Age 3** | I have a lot of life experience. (Ich habe viel Lebenserfahrung.) |\n",
    "| **Age 4** | Over time, my ability to react has decreased. (Im Laufe der Zeit hat meine Reaktionsfähigkeit abgenommen.) |\n",
    "| **Age 5** | Over time, my memory has deteriorated. (Im Laufe der Zeit hat meine Merkfähigkeit abgenommen.) |\n",
    "| **Age 6** | I worry a lot about getting older. (Ich mache mir viele Gedanken über das Älterwerden.) |\n",
    "| **Age 7** | I have already lived most of my life. (Den größten Teil meines Lebens habe ich bereits gelebt.) |\n",
    "| **Age 8** | I find it increasingly difficult to follow technical developments. (Ich habe zunehmend Schwierigkeiten technischen Weiterentwicklungen zu folgen.) |\n",
    "| **Age 9** | I have years of work experience. (Ich habe jahrelange Berufserfahrung.) |\n",
    "| **Age 10** | My whole life still lies ahead of me. (Mein ganzes Leben liegt noch vor mir.) |\n",
    "| **Age 11** | I used to be more willing to take risks. (Früher war ich risikofreudiger.) |\n",
    "| **Age 12** | I carry out everyday activities more slowly than before. (Ich verrichte Alltagstätigkeiten langsamer als früher.) |\n",
    "\n",
    "*Note:* Original wording in German shown in parenthesis.\n",
    "\n",
    "# Appendix C\n",
    "\n",
    "# Software versions\n",
    "\n",
    "Quarto ([Allaire et al., 2025](#ref-allaireQuarto2025)) version 1.7.32 and the extension apaquarto ([Schneider, 2025](#ref-schneiderApaquarto2025)) were used together with RStudio ([Posit team, 2025](#ref-positRstudio2025)) to build the manuscript and the manuscript website.  \n",
    "R (Version 4.5.1; [R Core Team, 2025b](#ref-R-base)) and the R-packages *corx* (Version 1.0.7.2; [Conigrave, 2023](#ref-R-corx)), *dplyr* (Version 1.1.4; [Wickham et al., 2023](#ref-R-dplyr)), *flextable* (Version 0.9.9; [Gohel & Skintzos, 2024](#ref-R-flextable)), *forcats* (Version 1.0.0; [Wickham, 2023a](#ref-R-forcats)), *foreign* (Version 0.8.90; [R Core Team, 2025a](#ref-R-foreign)), *ggplot2* (Version 3.5.2; [Wickham, 2016](#ref-R-ggplot2)), *lavaan* (Version 0.6.19; [Rosseel, 2012](#ref-R-lavaan)), *lubridate* (Version 1.9.4; [Grolemund & Wickham, 2011](#ref-R-lubridate)), *MBESS* (Version 4.9.3; [Kelley, 2023](#ref-R-MBESS)), *papaja* (Version 0.1.3; [Aust & Barth, 2024](#ref-R-papaja)), *psych* (Version 2.5.6; [William Revelle, 2025](#ref-R-psych)), *purrr* (Version 1.1.0; [Wickham & Henry, 2025](#ref-R-purrr)), *readr* (Version 2.1.5; [Wickham, Hester, et al., 2024](#ref-R-readr)), *semTools* (Version 0.5.7; [Jorgensen et al., 2025](#ref-R-semTools)), *stringr* (Version 1.5.1; [Wickham, 2023b](#ref-R-stringr)), *tibble* (Version 3.3.0; [Müller & Wickham, 2023](#ref-R-tibble)), *tidyr* (Version 1.3.1; [Wickham, Vaughan, et al., 2024](#ref-R-tidyr)), *tidyverse* (Version 2.0.0; [Wickham et al., 2019](#ref-R-tidyverse)) and *tinylabels* (Version 0.2.5; [Barth, 2025](#ref-R-tinylabels)) were used for data analysis.  \n",
    "Some dependencies are not included in this list but can be found in the `renv.lock` file in our online repository."
   ],
   "id": "a76d1c7d-46bb-4085-8074-c80c6e597559"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
